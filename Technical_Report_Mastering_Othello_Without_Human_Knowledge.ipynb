{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Technical Report: Mastering Othello Without Human Knowledge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewfeikema/alpha-zero-general/blob/master/Technical_Report_Mastering_Othello_Without_Human_Knowledge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwzNOOxwzVCI"
      },
      "source": [
        "# **Mastering Othello Without Human Knowledge**\n",
        "\n",
        "Can a small-scale model perform well at a simple board game without explicit provision of rules or examples? This project is inspired by advancements in general reinforcement learning demonstrated in the Go Game by Google's AlphaZero Model. However, the state space for Go is greater than the number of atoms in the observable universe, so we need a setting like 8x8 Othello with rapid board analysis and a limited set of legal moves.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idc4uFC31_TH"
      },
      "source": [
        "## **The reinforcement approach**\n",
        "\n",
        "Like AlphaZero, this model plays against itself to refine its approach. One major limitation to this approach is that it cannot acquire common strategies from natural gameplay, so the model's policy must balance exploration and exploitation to develop strategy. This is the advantage of the Monte Carlo method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDiYgl6eMaWt"
      },
      "source": [
        "## **Setup, install dependencies**\n",
        "\n",
        "The training process takes advantage of existing implementations for Othello's game logic, gameplay, and the tree search algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3HIlAhFE4rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccb75a2-36e7-4d59-c4ab-8b546afbf68a"
      },
      "source": [
        "# Clone repo and install requirements\n",
        "\n",
        "!git clone https://github.com/andrewfeikema/alpha-zero-general.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'alpha-zero-general'...\n",
            "remote: Enumerating objects: 1166, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 1166 (delta 50), reused 101 (delta 42), pack-reused 1051\u001b[K\n",
            "Receiving objects: 100% (1166/1166), 992.14 MiB | 36.65 MiB/s, done.\n",
            "Resolving deltas: 100% (626/626), done.\n",
            "Checking out files: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtAy44ZQbgH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eabdb019-a01a-4f7d-ae25-bfc95bdde5d6"
      },
      "source": [
        "%cd '/content/alpha-zero-general'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/alpha-zero-general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FINNt6pobz6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b36e6a-82d2-48f8-f467-5a5a9070d4a2"
      },
      "source": [
        "!git checkout -t origin/master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: A branch named 'master' already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-8kx3_iLSyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f535312-04db-4b07-bbbe-e1c7fda2159f"
      },
      "source": [
        "!pip install -r docker/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cffi==1.14.5 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 1)) (1.14.5)\n",
            "Collecting coloredlogs==14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/2f/12747be360d6dea432e7b5dfae3419132cb008535cfe614af73b9ce2643b/coloredlogs-14.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hCollecting cython==0.29.22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/c8/fa46acc8f829b64161a43315f42d2170de8ac961b251654cd81256520d98/Cython-0.29.22-cp37-cp37m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 4)) (1.1.2)\n",
            "Collecting gitpython==2.1.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/e5/fafe827507644c32d6dc553a1c435cdf882e0c28918a5bab29f7fbebfb70/GitPython-2.1.11-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 8)) (1.1.5)\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 165kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/2c/5edf2488897cad4fb8c4ace86369833552615bf264460ae4ef6e1f258982/scikit-learn-0.19.1.tar.gz (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 17.2MB/s \n",
            "\u001b[?25hCollecting scikit-image==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/ae/c9ea76fb37724596bd031e98f7f356936cabc39e5c57f27d56f08e6d52f2/scikit_image-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 1.3MB/s \n",
            "\u001b[?25hCollecting torchfile==0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting torchvision==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hCollecting tqdm==4.19.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/3c/341b4fa23cb3abc335207dba057c790f3bb329f6757e1fcd5d347bcf8308/tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hCollecting visdom==0.1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/f2/27b5d7c34b718afb355587d4e0c1f9108e925db4c0c932e935ba01051efd/visdom-0.1.7.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi==1.14.5->-r docker/requirements.txt (line 1)) (2.20)\n",
            "Collecting humanfriendly>=7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/66/363d01a81da2108a5cf446daf619779f06d49a0c4426dd02b40734f10e2f/humanfriendly-9.1-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (7.1.2)\n",
            "Collecting gitdb2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/52/7e/59f96b47f671b3fe0aa0c1b609531a540434b719a10c417581e25b383909/gitdb2-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r docker/requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (2.5.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (2.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.1->-r docker/requirements.txt (line 13)) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.7->-r docker/requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.7->-r docker/requirements.txt (line 15)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.7->-r docker/requirements.txt (line 15)) (22.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask==1.1.2->-r docker/requirements.txt (line 4)) (1.1.1)\n",
            "Collecting gitdb>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=1.8->scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.7/dist-packages (from dask[array]>=0.9.0->scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==0.2.1->-r docker/requirements.txt (line 13)) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (1.24.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: scikit-learn, torchfile, visdom\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5713 sha256=5b8cbe29afa7d3a9cfaa351eb78ff8f39930b5e6d09eaa467a84d9636c85c711\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.7-cp37-none-any.whl size=34498 sha256=c7e3746a0343453fb39999370c8cfa190919ba5de7e053a8edba99b543d1486a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/ea/0f/4e3a4b23f352c708d36d3a7ff654fb014f893f50baa88f2d29\n",
            "Successfully built torchfile visdom\n",
            "Failed to build scikit-learn\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pymc3 3.11.2 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: humanfriendly, coloredlogs, cython, smmap, gitdb, gitdb2, gitpython, scipy, scikit-learn, scikit-image, torchfile, torchvision, tqdm, visdom\n",
            "  Found existing installation: Cython 0.29.23\n",
            "    Uninstalling Cython-0.29.23:\n",
            "      Successfully uninstalled Cython-0.29.23\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "    Running setup.py install for scikit-learn ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of scikit-learn\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/scikit_learn-0.22.2.post1.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~cikit_learn-0.22.2.post1.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/sklearn/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~klearn\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_qoh_l69/scikit-learn/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_qoh_l69/scikit-learn/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-kp6hg10q/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJC2hqcSN0NY"
      },
      "source": [
        "# **Instantiate players**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRpskKggPHAo"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import Arena\n",
        "from MCTS import MCTS\n",
        "from othello.OthelloGame import OthelloGame\n",
        "from othello.OthelloPlayers import HumanOthelloPlayer, RandomPlayer, GreedyOthelloPlayer\n",
        "from othello.pytorch.NNet import NNetWrapper\n",
        "\n",
        "from utils import dotdict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJfaPANvQP9N"
      },
      "source": [
        "game = OthelloGame(n=8)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfwr_W5se8v"
      },
      "source": [
        "grp1 = GreedyOthelloPlayer(game).play"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7g7j_AfNoY3"
      },
      "source": [
        "numMCTSSims = 50"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufmxe9LOsg5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb12da4f-3507-43a7-97de-a85ac42933ba"
      },
      "source": [
        "nnet1 = NNetWrapper(game)\n",
        "nnet1.load_checkpoint(os.path.join('pretrained_models', 'othello', 'pytorch', '5-pm-checkpoints'), 'best.pth.tar')\n",
        "args1 = dotdict({'numMCTSSims': numMCTSSims, 'cpuct': 1.0})\n",
        "mcts1 = MCTS(game, nnet1, args1)\n",
        "alphazero1 = lambda x: np.argmax(mcts1.getActionProb(x, temp=0))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<othello.OthelloGame.OthelloGame at 0x7fd7e8422990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-QS9kRLPWKv"
      },
      "source": [
        "# **Play *Greedy Random* vs *AlphaZero***\n",
        "\n",
        "In playing 50 games, AlphaZero is considerably slower than the greedy approach. 50 games take roughly 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cSmiFO-tjsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b5c890-236e-47ae-fdbd-024b5d56b325"
      },
      "source": [
        "# Play Greedy Random vs AlphaZero\n",
        "player1 = grp1\n",
        "player2 = alphazero1\n",
        "arena = Arena.Arena(player1, player2, game, display=OthelloGame.display)\n",
        "%time oneWon, twoWon, draws = arena.playGames(50, verbose=False)\n",
        "print(\"\\nGreedy Random won {} games, Alpha Zero won {} games\".format(oneWon, twoWon))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [02:18<00:00,  5.53s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [02:08<00:00,  5.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 27s, sys: 1.66 s, total: 4min 28s\n",
            "Wall time: 4min 26s\n",
            "\n",
            "Greedy Random won 5 games, Alpha Zero won 45 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTff2UhV74BR"
      },
      "source": [
        "# **Tracking progress:**\n",
        "Checkpoint models against a greedy player"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF56CA_A610v",
        "outputId": "3f03a6ff-8dba-43ba-860c-847b5e19298d"
      },
      "source": [
        "# Show file locations of checkpoint models\n",
        "\n",
        "models3 = ['checkpoint_1.pth.tar', 'checkpoint_2.pth.tar', 'checkpoint_3.pth.tar', 'checkpoint_5.pth.tar', 'checkpoint_8.pth.tar', 'checkpoint_10.pth.tar' ]\n",
        "models5 = ['checkpoint_1.pth.tar', 'checkpoint_2.pth.tar', 'checkpoint_3.pth.tar', 'checkpoint_4.pth.tar', 'checkpoint_5.pth.tar', 'checkpoint_6.pth.tar', 'checkpoint_7.pth.tar', 'checkpoint_8.pth.tar', 'checkpoint_10.pth.tar' ]\n",
        "all_models = [(models3, '3-pm-checkpoints'), (models5, '5-pm-checkpoints')]\n",
        "all_models"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['checkpoint_1.pth.tar',\n",
              "   'checkpoint_2.pth.tar',\n",
              "   'checkpoint_3.pth.tar',\n",
              "   'checkpoint_5.pth.tar',\n",
              "   'checkpoint_8.pth.tar',\n",
              "   'checkpoint_10.pth.tar'],\n",
              "  '3-pm-checkpoints'),\n",
              " (['checkpoint_1.pth.tar',\n",
              "   'checkpoint_2.pth.tar',\n",
              "   'checkpoint_3.pth.tar',\n",
              "   'checkpoint_4.pth.tar',\n",
              "   'checkpoint_5.pth.tar',\n",
              "   'checkpoint_6.pth.tar',\n",
              "   'checkpoint_7.pth.tar',\n",
              "   'checkpoint_8.pth.tar',\n",
              "   'checkpoint_10.pth.tar'],\n",
              "  '5-pm-checkpoints')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKPf8ryE8fBR",
        "outputId": "6e03ad45-46c7-4e6c-838a-81e7eab7bc3c"
      },
      "source": [
        "args1 = dotdict({'numMCTSSims': numMCTSSims, 'cpuct': 1.0})\n",
        "player1 = grp1\n",
        "\n",
        "\n",
        "for set in all_models:\n",
        "  for checkpoint in set[0]:\n",
        "    nnetwrapper = NNetWrapper(game)\n",
        "    nnetwrapper.load_checkpoint(os.path.join('pretrained_models', 'othello', 'pytorch', set[1]), checkpoint)\n",
        "    mctstree = MCTS(game, nnetwrapper, args1)\n",
        "    alphazero1 = lambda x: np.argmax(mctstree.getActionProb(x, temp=0))\n",
        "    player2 = alphazero1\n",
        "    arena = Arena.Arena(player1, player2, game, display=OthelloGame.display)\n",
        "    %time oneWon, twoWon, draws = arena.playGames(50, verbose=False)\n",
        "    print(\"\\nGreedy Random won {} games, Alpha Zero won {} games\".format(oneWon, twoWon))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:31<00:00,  3.65s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:34<00:00,  3.76s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 5s, sys: 734 ms, total: 3min 5s\n",
            "Wall time: 3min 5s\n",
            "\n",
            "Greedy Random won 26 games, Alpha Zero won 24 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:36<00:00,  3.87s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:36<00:00,  3.86s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 13s, sys: 736 ms, total: 3min 14s\n",
            "Wall time: 3min 13s\n",
            "\n",
            "Greedy Random won 12 games, Alpha Zero won 38 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:39<00:00,  3.99s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:40<00:00,  4.03s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 20s, sys: 847 ms, total: 3min 21s\n",
            "Wall time: 3min 20s\n",
            "\n",
            "Greedy Random won 18 games, Alpha Zero won 32 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:41<00:00,  4.08s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:36<00:00,  3.86s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 18s, sys: 857 ms, total: 3min 19s\n",
            "Wall time: 3min 18s\n",
            "\n",
            "Greedy Random won 7 games, Alpha Zero won 43 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:42<00:00,  4.09s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:42<00:00,  4.09s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 24s, sys: 864 ms, total: 3min 25s\n",
            "Wall time: 3min 24s\n",
            "\n",
            "Greedy Random won 9 games, Alpha Zero won 41 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:43<00:00,  4.15s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:39<00:00,  4.00s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 23s, sys: 861 ms, total: 3min 24s\n",
            "Wall time: 3min 23s\n",
            "\n",
            "Greedy Random won 5 games, Alpha Zero won 45 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:29<00:00,  3.58s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:32<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 2s, sys: 619 ms, total: 3min 2s\n",
            "Wall time: 3min 2s\n",
            "\n",
            "Greedy Random won 24 games, Alpha Zero won 26 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:35<00:00,  3.81s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:35<00:00,  3.84s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 11s, sys: 710 ms, total: 3min 12s\n",
            "Wall time: 3min 11s\n",
            "\n",
            "Greedy Random won 9 games, Alpha Zero won 41 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:33<00:00,  3.76s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:37<00:00,  3.91s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 11s, sys: 732 ms, total: 3min 12s\n",
            "Wall time: 3min 11s\n",
            "\n",
            "Greedy Random won 17 games, Alpha Zero won 33 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:38<00:00,  3.95s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:39<00:00,  3.99s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 18s, sys: 860 ms, total: 3min 19s\n",
            "Wall time: 3min 18s\n",
            "\n",
            "Greedy Random won 7 games, Alpha Zero won 43 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:47<00:00,  4.30s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:37<00:00,  3.90s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 25s, sys: 869 ms, total: 3min 26s\n",
            "Wall time: 3min 25s\n",
            "\n",
            "Greedy Random won 7 games, Alpha Zero won 43 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:43<00:00,  4.13s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:41<00:00,  4.08s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 25s, sys: 983 ms, total: 3min 26s\n",
            "Wall time: 3min 25s\n",
            "\n",
            "Greedy Random won 5 games, Alpha Zero won 45 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:47<00:00,  4.29s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:50<00:00,  4.43s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 38s, sys: 1.11 s, total: 3min 39s\n",
            "Wall time: 3min 37s\n",
            "\n",
            "Greedy Random won 4 games, Alpha Zero won 46 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:43<00:00,  4.12s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:41<00:00,  4.07s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 25s, sys: 795 ms, total: 3min 25s\n",
            "Wall time: 3min 24s\n",
            "\n",
            "Greedy Random won 9 games, Alpha Zero won 41 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Arena.playGames (1): 100%|██████████| 25/25 [01:47<00:00,  4.28s/it]\n",
            "Arena.playGames (2): 100%|██████████| 25/25 [01:37<00:00,  3.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 25s, sys: 837 ms, total: 3min 26s\n",
            "Wall time: 3min 24s\n",
            "\n",
            "Greedy Random won 5 games, Alpha Zero won 45 games\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZG7aAEiNIV_"
      },
      "source": [
        "### **Result of evolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Mt67G0OpKsAd",
        "outputId": "7dc36581-5257-48fa-bca4-41fe3255ee71"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#note: neglected to export win counts from above cell for analysis- had to enter manually\n",
        "x = [1,2,3,5,8,11,12,13,14,15,16,17,18,20]\n",
        "y = [24,38,32,43,41,45,26,41,33,43,45,46,41,45]\n",
        "coef = np.polyfit(x,y,2)\n",
        "plt.plot(x, y, 'ro', x, np.poly1d(coef)(x), '--k')\n",
        "plt.axis([0,24,0, 50])\n",
        "plt.title('RL models against \\'greedy\\' player')\n",
        "plt.ylabel('Wins (n=50)')\n",
        "plt.xlabel('Iteration')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7opB7F2rO9x"
      },
      "source": [
        "The model appears to initially make quick progress after successive iterations. After 20 iterations of 10 epochs of self-play, there is still room for improvement in overcoming the 'greedy' strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9-lgefNW7Xh"
      },
      "source": [
        "# **Play against *AlphaZero***\n",
        "\n",
        "You can try playing against AlphaZero.\n",
        "You will play one game as the second player and one as the first player.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmKO4YJlSQai"
      },
      "source": [
        "# Play Greedy Random vs AlphaZero\n",
        "hp1 = HumanOthelloPlayer(game).play\n",
        "player1 = hp1\n",
        "player2 = alphazero1\n",
        "arena = Arena.Arena(player1, player2, game, display=OthelloGame.display)\n",
        "oneWon, twoWon, draws = arena.playGames(2, verbose=True)\n",
        "print(\"You won {} games, Alpha Zero won {} games\".format(oneWon, twoWon))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP1O2fVOqp2v"
      },
      "source": [
        "# **Exploring the model**\n",
        "\n",
        "#### **Uncovering shapes and connections**\n",
        "\n",
        "Given a board state, the MCTS algorithm provides a policy, a set of likelihoods of preference for each action. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF80yftgAiId"
      },
      "source": [
        "#### Model Architecture\n",
        "\n",
        "The Neural Network supplying the policy reccomendation analyzes the board with a 2D convolutional approach.\n",
        "\n",
        "From OthelloNNet.py:\n",
        "\n",
        "```\n",
        "        self.conv1 = nn.Conv2d(1, args.num_channels, 3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1)\n",
        "        self.conv4 = nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkJ3cmZLCpsm"
      },
      "source": [
        "#### Evolving Loss\n",
        "\n",
        "As each version of the model trained against its successor, the policy network's actions and loss measures are influenced by actions of its adversary. Initial training yielded high values for `Loss_pi`, associated with MCTS's selection in response to the policy network. In initial iterations, this value is extremely high:\n",
        "\n",
        "```\n",
        "2021-05-12 18:46:48 bb450b7c5a31 Coach[71] INFO Starting Iter #1 ...\n",
        "Self Play: 100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
        "Training Net:   0%|          | 0/7 [00:00<?, ?it/s]Checkpoint Directory exists! \n",
        "EPOCH ::: 1\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 45.38it/s, Loss_pi=4.01e+00, Loss_v=5.26e-01]\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 67.82it/s, Loss_pi=3.78e+00, Loss_v=1.57e-01]\n",
        "Training Net:   0%|          | 0/7 [00:00<?, ?it/s, Loss_pi=3.44e+00, Loss_v=1.04e-01]EPOCH ::: 2\n",
        "EPOCH ::: 3\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 68.10it/s, Loss_pi=3.42e+00, Loss_v=9.23e-02]\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 68.23it/s, Loss_pi=3.24e+00, Loss_v=5.44e-02]\n",
        "Training Net:   0%|          | 0/7 [00:00<?, ?it/s, Loss_pi=2.94e+00, Loss_v=2.89e-02]EPOCH ::: 4\n",
        "EPOCH ::: 5\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 66.67it/s, Loss_pi=2.90e+00, Loss_v=2.70e-02]\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 66.97it/s, Loss_pi=2.72e+00, Loss_v=4.55e-02]\n",
        "Training Net:   0%|          | 0/7 [00:00<?, ?it/s, Loss_pi=2.57e+00, Loss_v=2.81e-02]EPOCH ::: 6\n",
        "EPOCH ::: 7\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 68.32it/s, Loss_pi=2.54e+00, Loss_v=2.54e-02]\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 68.59it/s, Loss_pi=2.34e+00, Loss_v=1.53e-02]\n",
        "Training Net:   0%|          | 0/7 [00:00<?, ?it/s, Loss_pi=2.28e+00, Loss_v=4.20e-02]EPOCH ::: 8\n",
        "EPOCH ::: 9\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 67.98it/s, Loss_pi=2.25e+00, Loss_v=5.02e-02]\n",
        "Training Net: 100%|██████████| 7/7 [00:00<00:00, 70.25it/s, Loss_pi=1.96e+00, Loss_v=7.89e-02]\n",
        "2021-05-12 18:46:52 bb450b7c5a31 Coach[71] INFO PITTING AGAINST PREVIOUS VERSION\n",
        "Arena.playGames (1):   0%|          | 0/1 [00:00<?, ?it/s]EPOCH ::: 10\n",
        "Arena.playGames (1): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
        "Arena.playGames (2): 100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
        "2021-05-12 18:46:59 bb450b7c5a31 Coach[71] INFO NEW/PREV WINS : 1 / 1 ; DRAWS : 0\n",
        "2021-05-12 18:46:59 bb450b7c5a31 Coach[71] INFO REJECTING NEW MODEL\n",
        "CPU times: user 11.1 s, sys: 151 ms, total: 11.3 s\n",
        "Wall time: 11.3 s\n",
        "```\n",
        "\n",
        "By end of training, `Loss_pi` is significantly lower, but does not signal overconfidence, as the model improves play against the greedy approach.\n",
        "\n",
        "```\n",
        "Training Net:   0%|          | 0/1503 [00:00<?, ?it/s, Loss_pi=7.73e-01, Loss_v=3.41e-01]Checkpoint Directory exists! \n",
        "EPOCH ::: 1\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.66it/s, Loss_pi=6.79e-01, Loss_v=2.63e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:22, 67.90it/s, Loss_pi=6.21e-01, Loss_v=2.14e-01]EPOCH ::: 2\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.63it/s, Loss_pi=5.36e-01, Loss_v=2.04e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:22, 67.61it/s, Loss_pi=5.33e-01, Loss_v=2.06e-01]EPOCH ::: 3\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.55it/s, Loss_pi=4.76e-01, Loss_v=1.81e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:22, 66.80it/s, Loss_pi=4.82e-01, Loss_v=1.61e-01]EPOCH ::: 4\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.49it/s, Loss_pi=4.35e-01, Loss_v=1.69e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:21, 68.08it/s, Loss_pi=4.35e-01, Loss_v=1.92e-01]EPOCH ::: 5\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.70it/s, Loss_pi=4.20e-01, Loss_v=1.66e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:22, 67.97it/s, Loss_pi=4.56e-01, Loss_v=2.08e-01]EPOCH ::: 6\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.60it/s, Loss_pi=4.04e-01, Loss_v=1.59e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:21, 68.18it/s, Loss_pi=3.86e-01, Loss_v=1.77e-01]EPOCH ::: 7\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.57it/s, Loss_pi=3.94e-01, Loss_v=1.56e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:22, 67.67it/s, Loss_pi=3.73e-01, Loss_v=1.65e-01]EPOCH ::: 8\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.66it/s, Loss_pi=3.85e-01, Loss_v=1.55e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:21, 68.32it/s, Loss_pi=3.85e-01, Loss_v=1.46e-01]EPOCH ::: 9\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.80it/s, Loss_pi=3.79e-01, Loss_v=1.50e-01]\n",
        "Training Net:   0%|          | 7/1503 [00:00<00:21, 69.14it/s, Loss_pi=4.17e-01, Loss_v=1.69e-01]EPOCH ::: 10\n",
        "Training Net: 100%|██████████| 1503/1503 [00:22<00:00, 65.48it/s, Loss_pi=3.76e-01, Loss_v=1.55e-01]\n",
        "2021-05-12 21:02:50 bb450b7c5a31 Coach[71] INFO PITTING AGAINST PREVIOUS VERSION\n",
        "Arena.playGames (1): 100%|██████████| 2/2 [00:06<00:00,  3.34s/it]\n",
        "Arena.playGames (2): 100%|██████████| 2/2 [00:06<00:00,  3.38s/it]\n",
        "2021-05-12 21:03:03 bb450b7c5a31 Coach[71] INFO NEW/PREV WINS : 3 / 1 ; DRAWS : 0\n",
        "2021-05-12 21:03:03 bb450b7c5a31 Coach[71] INFO ACCEPTING NEW MODEL\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKdIvU-wGr0w"
      },
      "source": [
        "### **Other Considerations**\n",
        "\n",
        "#### Ideas for expansion:\n",
        "\n",
        "As the model progresses, one could track the exploitation of certain strategies. Capturing sides and corners is a common stratety- how often does this model prefer this approach when such a move is valid?\n",
        "\n",
        "Creating a graphical interface layering the policy and tree selections over the board state could show how the agent views common strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQKJs2HQHoH7"
      },
      "source": [
        "#### **Conclusion**\n",
        "\n",
        "This experiment demonstrates that small-scale generalized approaches combining Reinforcement Learning with advanced tree search methods can demonstrate competence in simple board games such as Othello. The final model outperformed a 'greedy' approach in 85% of matches after just 2 hours of training in the Colab environment."
      ]
    }
  ]
}