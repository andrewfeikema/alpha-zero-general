{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Othello Train Trial using AlphaZero General.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewfeikema/alpha-zero-general/blob/master/Othello_Train_Trial_using_AlphaZero_General.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkvJ-kBlWXHW"
      },
      "source": [
        "# **Setup, install dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji7OkVsnExHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644c4fbe-178c-4d59-9d96-221c1f08e793"
      },
      "source": [
        "# Clone repo and install requirements\n",
        "\n",
        "!git clone https://github.com/andrewfeikema/alpha-zero-general.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'alpha-zero-general'...\n",
            "remote: Enumerating objects: 1086, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 1086 (delta 7), reused 28 (delta 3), pack-reused 1051\u001b[K\n",
            "Receiving objects: 100% (1086/1086), 424.21 MiB | 32.49 MiB/s, done.\n",
            "Resolving deltas: 100% (583/583), done.\n",
            "Checking out files: 100% (144/144), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadDZdC2lQXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5361752-2d2a-4f49-9b44-3b24aebf428d"
      },
      "source": [
        "%cd '/content/alpha-zero-general'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/alpha-zero-general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvtLNTQTWl4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d2f1ba-a8f2-41ee-9626-cc3f36bb796a"
      },
      "source": [
        "!git checkout -t origin/master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: A branch named 'master' already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1483UJ1lS3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ce397a-3e27-4b4b-a73e-a4c32687994d"
      },
      "source": [
        "!pip install -r docker/requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cffi==1.14.5 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 1)) (1.14.5)\n",
            "Collecting coloredlogs==14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/2f/12747be360d6dea432e7b5dfae3419132cb008535cfe614af73b9ce2643b/coloredlogs-14.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython==0.29.22 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 3)) (0.29.22)\n",
            "Requirement already satisfied: flask==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 4)) (1.1.2)\n",
            "Collecting gitpython==2.1.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/e5/fafe827507644c32d6dc553a1c435cdf882e0c28918a5bab29f7fbebfb70/GitPython-2.1.11-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r docker/requirements.txt (line 8)) (1.1.5)\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 140kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/2c/5edf2488897cad4fb8c4ace86369833552615bf264460ae4ef6e1f258982/scikit-learn-0.19.1.tar.gz (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 34.9MB/s \n",
            "\u001b[?25hCollecting scikit-image==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/ae/c9ea76fb37724596bd031e98f7f356936cabc39e5c57f27d56f08e6d52f2/scikit_image-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 86kB/s \n",
            "\u001b[?25hCollecting torchfile==0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting torchvision==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hCollecting tqdm==4.19.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/3c/341b4fa23cb3abc335207dba057c790f3bb329f6757e1fcd5d347bcf8308/tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting visdom==0.1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/f2/27b5d7c34b718afb355587d4e0c1f9108e925db4c0c932e935ba01051efd/visdom-0.1.7.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi==1.14.5->-r docker/requirements.txt (line 1)) (2.20)\n",
            "Collecting humanfriendly>=7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/66/363d01a81da2108a5cf446daf619779f06d49a0c4426dd02b40734f10e2f/humanfriendly-9.1-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->-r docker/requirements.txt (line 4)) (1.1.0)\n",
            "Collecting gitdb2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/52/7e/59f96b47f671b3fe0aa0c1b609531a540434b719a10c417581e25b383909/gitdb2-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r docker/requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r docker/requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (2.5.1)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (2.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.1->-r docker/requirements.txt (line 13)) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.7->-r docker/requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.7->-r docker/requirements.txt (line 15)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom==0.1.7->-r docker/requirements.txt (line 15)) (22.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask==1.1.2->-r docker/requirements.txt (line 4)) (1.1.1)\n",
            "Collecting gitdb>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=1.8->scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.7/dist-packages (from dask[array]>=0.9.0->scikit-image==0.14.0->-r docker/requirements.txt (line 11)) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==0.2.1->-r docker/requirements.txt (line 13)) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom==0.1.7->-r docker/requirements.txt (line 15)) (3.0.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: scikit-learn, torchfile, visdom\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5713 sha256=8c832963710d9f4579265a293372a54a8b2f19ced5f932299113b0868f52d1b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.7-cp37-none-any.whl size=34498 sha256=75cdb9130d63834033733525ff3d92e29afd5a48b646bee1d5aa2ef62f6e89e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/ea/0f/4e3a4b23f352c708d36d3a7ff654fb014f893f50baa88f2d29\n",
            "Successfully built torchfile visdom\n",
            "Failed to build scikit-learn\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: humanfriendly, coloredlogs, smmap, gitdb, gitdb2, gitpython, scipy, scikit-learn, scikit-image, torchfile, torchvision, tqdm, visdom\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "    Running setup.py install for scikit-learn ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of scikit-learn\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/scikit_learn-0.22.2.post1.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~cikit_learn-0.22.2.post1.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/sklearn/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~klearn\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2so0rq2p/scikit-learn/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2so0rq2p/scikit-learn/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-zwshhi5e/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNEo96LdWxd8"
      },
      "source": [
        "# **Train AlphaZero**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsMxLhdKWO-H"
      },
      "source": [
        "import logging\n",
        "import coloredlogs\n",
        "from Coach import Coach\n",
        "from utils import dotdict\n",
        "from othello.keras.NNet import NNetWrapper\n",
        "from othello.OthelloGame import OthelloGame"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJi0kk_djiKm"
      },
      "source": [
        "log = logging.getLogger(__name__)\n",
        "coloredlogs.install(level='INFO')  # Change this to DEBUG to see more info."
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzIsb1wGVXkE"
      },
      "source": [
        "args = dotdict({\n",
        "    'numIters': 1000,\n",
        "    'numEps': 100,              # Number of complete self-play games to simulate during a new iteration.\n",
        "    'tempThreshold': 15,        #\n",
        "    'updateThreshold': 0.6,     # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n",
        "    'maxlenOfQueue': 200000,    # Number of game examples to train the neural networks.\n",
        "    'numMCTSSims': 25,          # Number of games moves for MCTS to simulate.\n",
        "    'arenaCompare': 40,         # Number of games to play during arena play to determine if new net will be accepted.\n",
        "    'cpuct': 1,\n",
        "    'checkpoint': './temp/',\n",
        "    'load_model': False,\n",
        "    'numItersForTrainExamplesHistory': 20,\n",
        "})"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8_4QdwlXZ3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0944ee51-42e4-4c52-a5ff-665af8826188"
      },
      "source": [
        "# If you have a pre-trained model, you can load it here.\n",
        "import os\n",
        "if os.path.exists(os.path.join('pretrained_models', 'othello', 'keras', '8x8', 'checkpoint.index')):\n",
        "  print (\"Using best pre-existing model\")\n",
        "  args['load_model'] = True\n",
        "  args['load_folder_file'] = ('pretrained_models/othello/keras/8x8','checkpoint.index')\n",
        "else:\n",
        "  print (\"Not using best pre-existing model\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using best pre-existing model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oIZd4tVXGjI"
      },
      "source": [
        "# Set very low iterations to let this notebook run in its entirety.\n",
        "\n",
        "# In reality, training a model, even as simple as the one for Dots and Boxes, can take several hours or days.\n",
        "args['numIters'] = 1\n",
        "args['numEps'] = 1\n",
        "args['arenaCompare'] = 2"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fKMHufYD3m"
      },
      "source": [
        "game = OthelloGame(n=8)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGKmzJ9kYF9O"
      },
      "source": [
        "nnet = NNetWrapper(game)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvkW0rl9YHeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42d14bcc-9d8a-458b-8bc1-18c016b4812b"
      },
      "source": [
        "if args.load_model:\n",
        "    print('Loading checkpoint \"{}/{}\"...'.format(args.load_folder_file[0], args.load_folder_file[1]))\n",
        "    nnet.load_checkpoint(args.load_folder_file[0], args.load_folder_file[1])\n",
        "else:\n",
        "    print('Not loading a checkpoint.')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint \"pretrained_models/othello/keras/8x8/checkpoint.index\"...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-fc7d89f7fd4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading checkpoint \"{}/{}\"...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_folder_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_folder_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_folder_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_folder_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not loading a checkpoint.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/alpha-zero-general/othello/keras/NNet.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(self, folder, filename)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No model in path {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2214\u001b[0m         \u001b[0;31m# streaming restore for any variables created in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m         \u001b[0mtrackable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m       \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_nontrivial_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_nontrivial_match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;31m# assert_nontrivial_match and assert_consumed (and both are less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;31m# useful since we don't touch Python objects or Python state).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_consumed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_saveable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_consumed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    998\u001b[0m       raise AssertionError(\n\u001b[1;32m    999\u001b[0m           \"Some objects had attributes which were not restored:{}\".format(\n\u001b[0;32m-> 1000\u001b[0;31m               \"\".join(unused_attribute_strings)))\n\u001b[0m\u001b[1;32m   1001\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrackable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Some objects had attributes which were not restored:\n    <tf.Variable 'conv2d_28/kernel:0' shape=(3, 3, 1, 512) dtype=float32, numpy=\narray([[[[ 0.00682934,  0.02717445,  0.01155422, ...,  0.02203334,\n          -0.02328168,  0.03485497]],\n\n        [[ 0.02189481,  0.02862032, -0.03276708, ...,  0.00292924,\n           0.00622577, -0.02635443]],\n\n        [[-0.007602  , -0.0105901 , -0.00729185, ...,  0.03426873,\n          -0.02992777, -0.0286784 ]]],\n\n\n       [[[-0.01284854,  0.01365831,  0.01287339, ...,  0.02676791,\n          -0.02903864, -0.01687833]],\n\n        [[-0.03010671,  0.02406989, -0.00838293, ..., -0.02208913,\n           0.01037191,  0.0049417 ]],\n\n        [[ 0.03397423, -0.01706493,  0.01773877, ...,  0.02826564,\n          -0.03239058, -0.02510511]]],\n\n\n       [[[-0.03508658, -0.03495044,  0.02740457, ..., -0.01556581,\n           0.01670728, -0.03394519]],\n\n        [[-0.03124822,  0.02018477,  0.022714  , ..., -0.01569637,\n           0.03184681,  0.02626273]],\n\n        [[-0.02101874,  0.00446153,  0.01826089, ..., -0.00035607,\n           0.02275565, -0.0050083 ]]]], dtype=float32)>: ['conv2d_28/kernel']\n    <tf.Variable 'batch_normalization_42/gamma:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_42/gamma']\n    <tf.Variable 'batch_normalization_42/beta:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_42/beta']\n    <tf.Variable 'batch_normalization_42/moving_mean:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_42/moving_mean']\n    <tf.Variable 'batch_normalization_42/moving_variance:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_42/moving_variance']\n    <tf.Variable 'conv2d_29/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\narray([[[[-1.48746762e-02, -1.03297327e-02, -1.57644600e-02, ...,\n           2.48374008e-02,  2.08927393e-02, -3.73249687e-03],\n         [-3.43602896e-03,  1.59722827e-02,  1.54506564e-02, ...,\n           8.61867890e-03,  2.89642252e-03,  2.40816846e-02],\n         [ 1.03696287e-02, -3.50892730e-03, -2.27781888e-02, ...,\n           2.85047479e-03,  1.29229017e-03,  1.63030811e-02],\n         ...,\n         [-1.34710595e-02, -2.00675651e-02,  1.45295970e-02, ...,\n           6.79669902e-03, -1.81320794e-02,  2.54629999e-02],\n         [-2.44936645e-02, -2.54468322e-02, -6.11592084e-04, ...,\n          -1.81936678e-02,  1.57667696e-03, -2.50108857e-02],\n         [-2.13858746e-02,  1.64155327e-02, -2.32559051e-02, ...,\n          -2.32398026e-02,  1.62955374e-04, -5.63605130e-03]],\n\n        [[ 1.52870566e-02,  2.76738219e-03, -1.49965752e-02, ...,\n          -3.41392867e-03,  1.51124522e-02,  2.01825127e-02],\n         [ 7.83135742e-03,  1.02890357e-02,  1.45079754e-02, ...,\n           1.89610384e-02,  3.18856351e-03, -2.50506345e-02],\n         [-5.56012429e-03,  1.08346902e-02,  2.18105428e-02, ...,\n          -1.54083706e-02,  2.60536931e-03, -5.34883700e-03],\n         ...,\n         [-2.91984901e-03,  2.40595415e-02,  2.13775523e-02, ...,\n          -2.59865262e-03, -3.63568589e-03,  1.72889307e-02],\n         [-2.31134389e-02, -1.45504382e-02,  8.11295211e-03, ...,\n           1.46246664e-02, -1.01774232e-02, -1.24374758e-02],\n         [ 1.76131502e-02,  1.90057904e-02, -1.36583121e-02, ...,\n          -2.16973200e-03, -1.75707303e-02,  2.07435153e-03]],\n\n        [[-2.85577029e-04,  7.77896866e-03, -1.37633355e-02, ...,\n          -2.08590496e-02, -1.10990489e-02, -1.20816939e-03],\n         [ 2.40595601e-02,  1.30416825e-02,  1.64882839e-02, ...,\n           5.75970858e-03, -1.19170491e-02, -2.05685440e-02],\n         [ 7.67240673e-03, -8.63745995e-03, -2.22124122e-02, ...,\n           1.56125426e-02,  4.52454016e-03, -1.49681168e-02],\n         ...,\n         [-1.14959944e-02, -1.51519440e-02,  1.67094879e-02, ...,\n           7.62577727e-03, -6.14108704e-03,  8.02369043e-03],\n         [-4.12798859e-03, -7.20815919e-03, -8.84422846e-03, ...,\n           1.14471801e-02,  2.02974081e-02,  4.03293036e-03],\n         [-1.87489875e-02, -1.82123259e-02,  5.80796599e-03, ...,\n           1.63110942e-02,  1.31925792e-02,  9.29806381e-04]]],\n\n\n       [[[ 4.15332615e-03, -7.89911486e-03, -1.98237132e-02, ...,\n          -7.79325888e-03, -1.94975957e-02,  1.68312341e-02],\n         [-2.14216821e-02,  6.64280728e-03, -1.37137491e-02, ...,\n          -1.97149813e-04,  2.13866234e-02, -6.53171167e-03],\n         [-2.07104329e-02,  3.75439599e-03, -1.75716672e-02, ...,\n          -1.45119252e-02, -6.61931932e-04,  1.49604455e-02],\n         ...,\n         [ 2.49501914e-02, -1.14682671e-02, -1.21891098e-02, ...,\n          -7.21634179e-03,  8.27481970e-03, -5.03497198e-03],\n         [-1.41039435e-02,  1.27063245e-02,  1.75090805e-02, ...,\n          -1.29733365e-02,  2.32206397e-02, -3.40094045e-03],\n         [-7.34672695e-03,  1.07724927e-02, -1.96345579e-02, ...,\n          -2.28708573e-02, -2.24419422e-02,  1.56594440e-02]],\n\n        [[-4.66874056e-03, -2.22979076e-02,  1.62755921e-02, ...,\n           3.27727757e-03,  2.07374170e-02,  1.20377876e-02],\n         [-2.11290605e-02,  6.96161389e-03,  3.25229950e-03, ...,\n           2.08259784e-02, -2.17629895e-02,  7.57633150e-03],\n         [ 6.63119555e-03, -5.68513200e-03, -2.06704959e-02, ...,\n          -2.47749649e-02,  5.87225705e-03,  6.50307909e-03],\n         ...,\n         [-8.55978578e-04, -1.60491392e-02,  8.72614235e-03, ...,\n          -6.36059791e-04, -1.78849921e-02,  7.63207301e-03],\n         [-1.32135870e-02, -1.99672207e-02,  8.76387209e-03, ...,\n          -1.85200348e-02,  8.47167522e-03,  5.01310825e-03],\n         [ 6.83832541e-03, -3.35092284e-03, -7.31529295e-03, ...,\n          -2.48875208e-02,  2.53450684e-02, -2.19262671e-02]],\n\n        [[-2.28462201e-02,  8.32080096e-03, -1.95828192e-02, ...,\n           2.03732252e-02,  4.58364561e-03,  7.20560551e-03],\n         [ 2.06836350e-02, -1.06418319e-03, -4.84451838e-03, ...,\n          -2.42956802e-02,  1.23057663e-02, -1.70165468e-02],\n         [-2.90973857e-03,  2.09907666e-02,  2.08376832e-02, ...,\n           8.66372883e-03,  7.09344447e-03,  9.13589075e-03],\n         ...,\n         [ 2.10606493e-03, -9.75621119e-03,  3.41368839e-04, ...,\n          -3.41791287e-03,  2.37234607e-02,  1.93599239e-02],\n         [ 2.10195035e-02, -1.53044304e-02,  1.23545229e-02, ...,\n          -6.71574660e-03,  5.59108332e-03,  3.21138836e-03],\n         [ 5.45580685e-03, -1.68574899e-02,  7.03484565e-03, ...,\n          -6.83268718e-03,  6.00193441e-03,  2.26706117e-02]]],\n\n\n       [[[ 1.58247836e-02,  5.53084537e-03, -2.08966807e-02, ...,\n           1.83843561e-02, -2.52097510e-02,  1.28122345e-02],\n         [-2.46343780e-02, -6.97114505e-03,  7.69802928e-03, ...,\n          -4.23847511e-03,  7.11824000e-03,  1.27828643e-02],\n         [-8.51383992e-03, -1.54103907e-02, -2.44927816e-02, ...,\n           2.20683813e-02,  1.37005374e-02, -1.04803881e-02],\n         ...,\n         [-2.07359828e-02,  7.23893940e-03, -2.13440955e-02, ...,\n           1.90734453e-02,  1.70492195e-02, -2.20921244e-02],\n         [ 2.12641396e-02,  6.16556033e-03,  1.05086155e-02, ...,\n          -2.02889945e-02, -1.17700873e-02, -1.17539298e-02],\n         [-2.35650912e-02,  2.04282366e-02, -2.23169234e-02, ...,\n          -1.57507174e-02,  1.34231597e-02,  1.49864703e-02]],\n\n        [[ 1.25858933e-04, -2.09346842e-02,  9.81028751e-03, ...,\n           2.28027590e-02,  1.07965246e-03, -6.25337288e-03],\n         [ 3.57839838e-03, -1.71907619e-02, -6.13353215e-03, ...,\n           9.06951353e-03,  2.04726569e-02, -5.66045754e-03],\n         [ 1.66881233e-02, -2.22988985e-02, -2.36612223e-02, ...,\n           1.94916055e-02,  2.10535899e-03, -1.80626251e-02],\n         ...,\n         [ 2.55290605e-03,  2.49745362e-02,  2.37071998e-02, ...,\n          -1.72644388e-02,  1.23766661e-02,  1.17413662e-02],\n         [ 2.05745064e-02, -1.23392846e-02, -4.22509387e-04, ...,\n           1.14773214e-03, -1.84597541e-02, -1.54682072e-02],\n         [-5.81628270e-03,  2.37192996e-02,  5.48180193e-03, ...,\n          -2.00305786e-02, -6.98590651e-04,  3.51789407e-03]],\n\n        [[ 2.28867978e-02,  9.78785753e-03, -1.38699161e-02, ...,\n          -1.31212594e-02, -6.67035766e-03, -2.09092982e-02],\n         [-9.39462334e-05, -1.95151716e-02, -6.19890168e-04, ...,\n           6.54094666e-03, -2.15935800e-02,  1.90509297e-03],\n         [-2.02606209e-02,  1.35656297e-02,  3.03859077e-03, ...,\n           1.08349137e-02,  1.00099482e-03,  2.21652947e-02],\n         ...,\n         [ 6.13840297e-03,  4.72905114e-03, -1.99759677e-02, ...,\n          -2.39464082e-03, -2.11394392e-02, -1.42799476e-02],\n         [-5.83126023e-03,  1.76523253e-02, -1.91495568e-03, ...,\n          -4.19397466e-03, -3.92986648e-03,  2.35928744e-02],\n         [-2.48890650e-02,  7.13221356e-03, -8.22918117e-03, ...,\n          -3.57847661e-04, -4.90948930e-03,  2.50141807e-02]]]],\n      dtype=float32)>: ['conv2d_29/kernel']\n    <tf.Variable 'batch_normalization_43/gamma:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_43/gamma']\n    <tf.Variable 'batch_normalization_43/beta:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_43/beta']\n    <tf.Variable 'batch_normalization_43/moving_mean:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_43/moving_mean']\n    <tf.Variable 'batch_normalization_43/moving_variance:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_43/moving_variance']\n    <tf.Variable 'conv2d_30/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\narray([[[[-0.00674959,  0.00477879, -0.00866158, ..., -0.01284875,\n          -0.00035683,  0.01672411],\n         [ 0.0044269 , -0.00155291, -0.00296332, ..., -0.0208783 ,\n          -0.01232302,  0.01754645],\n         [ 0.00602701, -0.02269007,  0.02149047, ...,  0.00930464,\n           0.00517787, -0.02335703],\n         ...,\n         [-0.01039677, -0.00118095, -0.02062937, ...,  0.01310621,\n          -0.0008801 , -0.00839116],\n         [ 0.02390918, -0.02166159,  0.00226987, ..., -0.00288034,\n           0.01243122, -0.00295957],\n         [ 0.02011162,  0.00223675, -0.01750309, ...,  0.0176858 ,\n          -0.00043997, -0.00676016]],\n\n        [[-0.01025887,  0.01853572,  0.00795617, ...,  0.01299524,\n          -0.00114877, -0.00608413],\n         [-0.02375092, -0.0030418 ,  0.00053449, ..., -0.0024448 ,\n           0.01776163, -0.00840891],\n         [ 0.00759814, -0.00411646, -0.01605687, ..., -0.01625622,\n          -0.02131349, -0.0139655 ],\n         ...,\n         [ 0.00903323, -0.02010415, -0.02002404, ...,  0.01255076,\n          -0.00524475, -0.00933014],\n         [-0.01954129, -0.00210591, -0.00225616, ..., -0.02496008,\n          -0.00684067, -0.00063566],\n         [ 0.0055828 ,  0.00961936,  0.00969887, ...,  0.02545027,\n           0.02113115, -0.01435659]],\n\n        [[ 0.0133709 , -0.02258675, -0.01053392, ...,  0.00594596,\n           0.01410624, -0.01953208],\n         [-0.02310946,  0.02124721,  0.00366461, ...,  0.00194719,\n           0.00099685,  0.0108753 ],\n         [-0.01628386,  0.01559414, -0.01477945, ..., -0.02537151,\n           0.02200161,  0.00931972],\n         ...,\n         [ 0.01729882, -0.02282556, -0.01282822, ..., -0.01901156,\n          -0.02413481,  0.00572124],\n         [ 0.01922116, -0.00209817, -0.00676123, ..., -0.0208372 ,\n           0.02197111, -0.02068091],\n         [-0.00113014, -0.01167111,  0.00203468, ..., -0.00953778,\n          -0.0152338 , -0.02442186]]],\n\n\n       [[[-0.00440445,  0.02094759,  0.01236645, ..., -0.01344209,\n          -0.01759758, -0.01642922],\n         [ 0.00406746,  0.00612988, -0.02459147, ...,  0.0084214 ,\n           0.02352624, -0.00137538],\n         [-0.02133248,  0.00054098,  0.02417646, ...,  0.02410398,\n          -0.01605102, -0.01117014],\n         ...,\n         [ 0.01847681,  0.00814642,  0.00448285, ...,  0.0035201 ,\n           0.01845029, -0.010011  ],\n         [ 0.00849694, -0.01239953,  0.01383699, ...,  0.01240104,\n          -0.02509027,  0.02103058],\n         [-0.01896049, -0.02169391,  0.02273022, ...,  0.01199739,\n           0.00899242, -0.00339008]],\n\n        [[-0.01883118, -0.01994952,  0.01200755, ..., -0.01721336,\n          -0.01874248,  0.02390239],\n         [-0.00926248, -0.00076234, -0.0002869 , ...,  0.02408516,\n           0.02140463, -0.00908217],\n         [-0.02073454, -0.00080158,  0.00163173, ...,  0.01493923,\n          -0.02517902, -0.00273914],\n         ...,\n         [ 0.01513354, -0.00833857,  0.02450925, ..., -0.01384528,\n          -0.01185378, -0.02547757],\n         [-0.00842539,  0.01535908,  0.01803704, ..., -0.01370691,\n          -0.01722315, -0.01177918],\n         [-0.01861281,  0.02325325, -0.01919866, ..., -0.00025854,\n           0.00546418, -0.02240361]],\n\n        [[ 0.01504868,  0.01700518, -0.02108775, ...,  0.00434237,\n           0.02345274, -0.00624186],\n         [-0.00643598, -0.01870615,  0.0165473 , ..., -0.02198325,\n          -0.00479274,  0.01117822],\n         [ 0.00367413, -0.00986126, -0.00254916, ..., -0.01118158,\n          -0.01181798,  0.02074373],\n         ...,\n         [ 0.01047842,  0.00026265, -0.02084848, ..., -0.02205075,\n          -0.00910477,  0.01834138],\n         [ 0.01767177,  0.01245536, -0.02396082, ..., -0.01637866,\n          -0.02141144, -0.02320437],\n         [-0.00995622, -0.00577511,  0.0126003 , ...,  0.0146125 ,\n           0.01681111, -0.01276299]]],\n\n\n       [[[-0.01022406, -0.02031847,  0.01890764, ..., -0.00846854,\n          -0.00789026, -0.0044774 ],\n         [ 0.02030968,  0.02133406, -0.01459847, ..., -0.01571788,\n          -0.00546165,  0.00048683],\n         [ 0.01160041,  0.02015259,  0.02459928, ..., -0.01126158,\n          -0.00906014,  0.01007019],\n         ...,\n         [-0.01171063,  0.00482445,  0.00275503, ..., -0.01204711,\n          -0.00577355,  0.00357143],\n         [ 0.01583161, -0.0235319 , -0.00698295, ...,  0.01613038,\n          -0.01507925,  0.00891946],\n         [-0.01807752,  0.01348337, -0.02452591, ..., -0.01856378,\n          -0.02067329,  0.02131547]],\n\n        [[ 0.00270345, -0.02419309,  0.01882528, ...,  0.00306079,\n           0.00316905, -0.00860154],\n         [ 0.02123657,  0.02494023, -0.00714576, ...,  0.02370609,\n          -0.00020353, -0.00473149],\n         [-0.00653797, -0.00044932, -0.00563308, ..., -0.00971599,\n          -0.0031525 ,  0.00514978],\n         ...,\n         [ 0.00138473, -0.00851577,  0.01623633, ..., -0.00824897,\n          -0.0079573 , -0.00750505],\n         [ 0.01863938, -0.0187142 , -0.00805105, ...,  0.00951893,\n          -0.01065208,  0.00054131],\n         [-0.00694011, -0.00408993, -0.01658072, ..., -0.02491676,\n          -0.01980944, -0.01614321]],\n\n        [[-0.00625553, -0.00025075, -0.0169659 , ...,  0.01649439,\n          -0.00793441, -0.01597114],\n         [ 0.01693944, -0.00482564, -0.00886633, ..., -0.02248031,\n          -0.00727897, -0.01364411],\n         [ 0.01484267,  0.00367995,  0.02087437, ...,  0.00922959,\n           0.00311631, -0.01079992],\n         ...,\n         [ 0.01126868, -0.0119551 , -0.00194902, ..., -0.01274247,\n          -0.02276798,  0.02014272],\n         [ 0.00512443,  0.00242574,  0.02231227, ...,  0.01583115,\n           0.00268899,  0.00464225],\n         [-0.00990378, -0.02215683, -0.00650071, ..., -0.00908544,\n           0.00746842, -0.01900328]]]], dtype=float32)>: ['conv2d_30/kernel']\n    <tf.Variable 'batch_normalization_44/gamma:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_44/gamma']\n    <tf.Variable 'batch_normalization_44/beta:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_44/beta']\n    <tf.Variable 'batch_normalization_44/moving_mean:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_44/moving_mean']\n    <tf.Variable 'batch_normalization_44/moving_variance:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_44/moving_variance']\n    <tf.Variable 'conv2d_31/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\narray([[[[ 1.21494234e-02, -6.65753521e-03,  2.97734886e-03, ...,\n           4.24842723e-03,  1.56958327e-02,  4.82513756e-03],\n         [-5.35255298e-03, -4.84399498e-03, -2.42670216e-02, ...,\n          -1.37927970e-02, -2.87679024e-03,  2.38983519e-02],\n         [ 3.96562740e-04,  3.82565707e-03, -1.35342777e-02, ...,\n           1.16480775e-02,  1.85870901e-02, -1.72439255e-02],\n         ...,\n         [ 1.81878321e-02,  3.98277864e-03,  3.08959372e-03, ...,\n           4.56537120e-03,  2.33618952e-02,  6.26311824e-03],\n         [ 1.01462752e-02, -1.25043504e-02, -1.60857961e-02, ...,\n          -1.36247193e-02,  1.22959055e-02, -4.45706956e-03],\n         [-1.27034411e-02,  2.11388469e-02, -1.87883116e-02, ...,\n           1.95009895e-02, -1.84517968e-02, -2.43999381e-02]],\n\n        [[-8.90613161e-03, -2.29489058e-04,  2.16879956e-02, ...,\n           1.80735141e-02,  1.70984417e-02, -1.05804894e-02],\n         [-1.12165613e-02, -1.86023191e-02, -2.49277800e-04, ...,\n          -1.56826582e-02,  1.35775805e-02, -2.09848043e-02],\n         [ 1.99836716e-02,  8.13384727e-03,  1.58715881e-02, ...,\n           1.86009444e-02,  2.45876946e-02,  1.67792477e-02],\n         ...,\n         [ 2.15165690e-02,  2.36312784e-02, -1.23707838e-02, ...,\n          -1.77831985e-02,  1.58207752e-02,  2.39324719e-02],\n         [ 4.63077985e-03, -7.42109492e-03,  1.46915056e-02, ...,\n          -1.52144581e-03, -2.41653994e-02,  2.40505151e-02],\n         [ 5.09514101e-03,  1.37577914e-02,  1.90097466e-03, ...,\n           2.90891156e-03, -9.30031575e-03,  1.96781382e-03]],\n\n        [[ 5.83372265e-03, -2.01499090e-04, -5.69575280e-03, ...,\n          -2.63146684e-03,  2.74080969e-03, -1.73238963e-02],\n         [ 1.61240324e-02,  1.72886439e-02,  1.76918581e-02, ...,\n           5.65134548e-03, -2.25728508e-02, -1.66669171e-02],\n         [ 1.24112442e-02,  2.30999663e-03,  1.97948478e-02, ...,\n          -5.07051684e-03,  2.25788429e-02,  1.21155120e-02],\n         ...,\n         [ 2.32410245e-02, -1.92092508e-02, -1.59381293e-02, ...,\n          -1.96009539e-02,  1.26457810e-02,  2.47419439e-02],\n         [-1.09914523e-02,  1.04601122e-03, -1.56215932e-02, ...,\n          -1.95190161e-02, -1.41584501e-03,  3.38329934e-03],\n         [-2.38592289e-02, -1.55737596e-02, -4.00838442e-03, ...,\n           2.41447836e-02, -1.92032754e-02, -5.94534725e-03]]],\n\n\n       [[[-1.70325227e-02, -1.37682259e-02,  3.37870046e-03, ...,\n          -3.48687172e-04,  4.13360074e-04,  2.65258737e-03],\n         [-1.13019897e-02, -7.76196457e-03, -7.67016783e-03, ...,\n           2.22754180e-02, -1.26778483e-02, -1.07726874e-02],\n         [ 2.51498111e-02,  3.06930393e-04, -3.95947322e-03, ...,\n           1.34507529e-02, -1.35417236e-02, -1.03563117e-02],\n         ...,\n         [ 1.07851699e-02,  1.80443861e-02, -1.21909231e-02, ...,\n           1.53039694e-02, -3.66008095e-03, -1.36514315e-02],\n         [-2.43021119e-02, -1.61379576e-04, -9.11754742e-03, ...,\n           3.13019380e-03,  1.66401640e-02, -1.76550820e-02],\n         [-1.56116588e-02, -2.28331462e-02, -1.28441863e-03, ...,\n           7.24768266e-03, -3.94232571e-04,  2.04598345e-02]],\n\n        [[-1.57209337e-02, -3.93118523e-03,  2.48854980e-03, ...,\n           1.80729143e-02,  4.53899428e-03,  2.13403888e-02],\n         [-1.10201659e-02, -2.42977794e-02, -1.33527564e-02, ...,\n           7.32225180e-03,  4.96505573e-03, -3.44724022e-03],\n         [-2.48774104e-02, -9.70031135e-03,  1.58860534e-03, ...,\n           3.18351388e-03,  1.60926767e-02,  5.02804853e-03],\n         ...,\n         [ 7.77282938e-03, -7.83290341e-03, -1.57418847e-02, ...,\n           3.68095934e-05, -2.31638756e-02, -3.62789258e-03],\n         [-2.32985485e-02, -1.94301493e-02,  2.30142139e-02, ...,\n           4.03079391e-03,  1.04846172e-02,  2.23765485e-02],\n         [ 2.03649513e-02, -7.62418844e-03, -5.20499423e-04, ...,\n           1.76758394e-02, -2.19381787e-02,  1.98412277e-02]],\n\n        [[-1.11927269e-02, -1.36208385e-02, -7.32469186e-03, ...,\n          -8.35164450e-03,  2.51548775e-02,  2.88225338e-03],\n         [ 2.19635330e-02,  1.68932602e-02,  4.76606190e-03, ...,\n          -9.94727761e-03, -2.54370254e-02, -1.00151012e-02],\n         [-1.57198943e-02, -1.18357632e-02, -2.25020051e-02, ...,\n           5.80295548e-03, -1.14204884e-02,  1.75386705e-02],\n         ...,\n         [-1.82172656e-03,  1.60997994e-02, -2.50693820e-02, ...,\n          -2.26339400e-02,  3.06480937e-03,  4.84179892e-03],\n         [ 1.41363554e-02,  1.25150010e-02, -4.23938036e-04, ...,\n           2.07266621e-02,  6.63591921e-03,  2.17683986e-02],\n         [ 1.92289725e-02,  7.75505602e-03,  1.91899464e-02, ...,\n          -1.04636224e-02, -1.69862397e-02,  1.69735625e-02]]],\n\n\n       [[[-4.58916277e-03, -1.28059098e-02, -8.09683651e-03, ...,\n           1.59768201e-02,  1.25790499e-02, -6.33108802e-03],\n         [-1.50895165e-02,  6.22476265e-03, -9.60168056e-03, ...,\n           1.31675117e-02, -1.21169183e-02,  5.94519079e-05],\n         [ 1.20505132e-02,  1.37105919e-02,  2.38060169e-02, ...,\n          -1.44893369e-02,  1.64097548e-02, -1.02312248e-02],\n         ...,\n         [ 7.11878389e-03,  9.22345743e-03, -1.64999403e-02, ...,\n           1.38894320e-02,  1.17154904e-02,  2.40683705e-02],\n         [ 2.07315832e-02,  3.53095494e-03,  2.18928531e-02, ...,\n           1.99759193e-02,  1.82512403e-02, -4.48928028e-03],\n         [ 8.23490322e-03, -2.02477071e-02, -3.11682932e-03, ...,\n          -7.77834840e-03, -2.63586640e-04, -2.46381927e-02]],\n\n        [[-1.91597864e-02,  1.25919878e-02, -2.40803901e-02, ...,\n           5.92269376e-03, -3.27148661e-03,  1.30461529e-03],\n         [-1.76731069e-02, -7.35241920e-04,  2.13745609e-02, ...,\n          -2.23553944e-02, -1.64679065e-02,  2.45952494e-02],\n         [ 2.69759260e-03,  2.31092945e-02,  1.77330598e-02, ...,\n          -2.02140175e-02,  6.93879277e-03,  2.33788677e-02],\n         ...,\n         [ 9.92462784e-03,  2.18417197e-02, -1.85020156e-02, ...,\n           1.43667199e-02,  1.83934271e-02, -1.03572300e-02],\n         [-1.30061992e-03,  1.71361566e-02, -2.20233221e-02, ...,\n           2.24732123e-02,  1.12977996e-03, -2.23714374e-02],\n         [ 1.40086785e-02, -2.12328359e-02,  1.88341998e-02, ...,\n          -6.65590353e-03,  1.78395770e-02,  1.89336129e-02]],\n\n        [[-1.59573890e-02, -2.28633918e-03, -3.13508511e-03, ...,\n          -2.09015775e-02,  1.42668448e-02,  1.04276016e-02],\n         [ 2.09909193e-02, -1.53580680e-04, -3.07218358e-03, ...,\n           1.49772353e-02, -1.10611916e-02,  3.46807577e-03],\n         [ 4.92591411e-03,  6.17048144e-03,  2.44492367e-02, ...,\n           8.99815559e-03,  7.69462064e-03,  4.13527153e-03],\n         ...,\n         [ 7.25716352e-04,  3.32463533e-05,  1.65601298e-02, ...,\n          -1.34158833e-02, -1.06326910e-02,  3.70758586e-03],\n         [-3.87206115e-03, -2.71298364e-03,  2.35379599e-02, ...,\n          -2.03891881e-02, -5.28937206e-03,  6.43591210e-03],\n         [ 5.68404235e-03, -9.53139365e-03, -1.41125452e-02, ...,\n           5.29801100e-03, -1.89926699e-02, -1.20621929e-02]]]],\n      dtype=float32)>: ['conv2d_31/kernel']\n    <tf.Variable 'batch_normalization_45/gamma:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_45/gamma']\n    <tf.Variable 'batch_normalization_45/beta:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_45/beta']\n    <tf.Variable 'batch_normalization_45/moving_mean:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_45/moving_mean']\n    <tf.Variable 'batch_normalization_45/moving_variance:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_45/moving_variance']\n    <tf.Variable 'dense_14/kernel:0' shape=(8192, 1024) dtype=float32, numpy=\narray([[ 0.00592648, -0.01315849,  0.01105655, ..., -0.02296211,\n        -0.00148448, -0.00494329],\n       [ 0.0246391 , -0.0218009 , -0.00726531, ...,  0.02478901,\n        -0.0071018 ,  0.01507836],\n       [ 0.00255642,  0.00150622, -0.01521946, ...,  0.01595917,\n        -0.02430422, -0.01318407],\n       ...,\n       [ 0.00790855, -0.0008202 ,  0.0183356 , ...,  0.00452748,\n         0.01980312,  0.01770465],\n       [-0.01724595,  0.01238324, -0.00227369, ..., -0.01521782,\n        -0.01410426, -0.01770033],\n       [ 0.00628977,  0.02120676,  0.01922421, ...,  0.00057412,\n         0.00166951, -0.0150754 ]], dtype=float32)>: ['dense_14/kernel']\n    <tf.Variable 'batch_normalization_46/gamma:0' shape=(1024,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>: ['batch_normalization_46/gamma']\n    <tf.Variable 'batch_normalization_46/beta:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>: ['batch_normalization_46/beta']\n    <tf.Variable 'batch_normalization_46/moving_mean:0' shape=(1024,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>: ['batch_normalization_46/moving_mean']\n    <tf.Variable 'batch_normalization_46/moving_variance:0' shape=(1024,) dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>: ['batch_normalization_46/moving_variance']\n    <tf.Variable 'dense_15/kernel:0' shape=(1024, 512) dtype=float32, numpy=\narray([[-0.04158697,  0.04163602,  0.00602534, ..., -0.02906552,\n        -0.01049858, -0.01096271],\n       [-0.04199353, -0.0099576 ,  0.03133148, ...,  0.02281329,\n         0.02977884, -0.00838363],\n       [-0.0192382 ,  0.0612229 ,  0.02086246, ..., -0.0328621 ,\n         0.05450584,  0.03408726],\n       ...,\n       [ 0.01783089, -0.03875081,  0.05698405, ..., -0.01057594,\n        -0.04909576,  0.01773669],\n       [ 0.01037838,  0.05964491,  0.01146458, ...,  0.04729155,\n         0.02509706,  0.03009415],\n       [-0.01435035,  0.04911132,  0.0455575 , ..., -0.00310913,\n        -0.01564942,  0.00628825]], dtype=float32)>: ['dense_15/kernel']\n    <tf.Variable 'batch_normalization_47/gamma:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_47/gamma']\n    <tf.Variable 'batch_normalization_47/beta:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_47/beta']\n    <tf.Variable 'batch_normalization_47/moving_mean:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>: ['batch_normalization_47/moving_mean']\n    <tf.Variable 'batch_normalization_47/moving_variance:0' shape=(512,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>: ['batch_normalization_47/moving_variance']\n    <tf.Variable 'pi/kernel:0' shape=(512, 65) dtype=float32, numpy=\narray([[ 0.04069015, -0.03040925,  0.05710314, ...,  0.02254557,\n        -0.07863909, -0.09827052],\n       [ 0.03492068,  0.06644185, -0.00612611, ...,  0.09190398,\n         0.01155165, -0.02062892],\n       [ 0.03121476,  0.00468993,  0.09429662, ..., -0.06174374,\n        -0.00634364,  0.02534473],\n       ...,\n       [ 0.09487839,  0.06098138, -0.05217229, ..., -0.07766972,\n         0.03151982, -0.07813597],\n       [-0.02716694, -0.09220244, -0.08871967, ...,  0.01837879,\n         0.06236629, -0.07468852],\n       [ 0.05802071,  0.05005199,  0.08742563, ..., -0.00015885,\n         0.04456753,  0.02302693]], dtype=float32)>: ['pi/kernel']\n    <tf.Variable 'pi/bias:0' shape=(65,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>: ['pi/bias']\n    <tf.Variable 'v/kernel:0' shape=(512, 1) dtype=float32, numpy=\narray([[ 0.10625347],\n       [-0.08306319],\n       [ 0.04926584],\n       [-0.09815851],\n       [-0.06456104],\n       [-0.06164962],\n       [-0.09778605],\n       [ 0.0797505 ],\n       [ 0.05864819],\n       [-0.07534367],\n       [ 0.01820632],\n       [ 0.0179579 ],\n       [ 0.05403867],\n       [ 0.0783835 ],\n       [ 0.08975966],\n       [ 0.07671506],\n       [-0.05489305],\n       [ 0.06635151],\n       [-0.1005424 ],\n       [ 0.0712809 ],\n       [ 0.03230723],\n       [-0.10259229],\n       [ 0.10229827],\n       [ 0.03527296],\n       [ 0.05250604],\n       [-0.0860936 ],\n       [ 0.10184928],\n       [ 0.01237942],\n       [ 0.06385749],\n       [ 0.02824738],\n       [-0.01768743],\n       [ 0.04571807],\n       [ 0.10812788],\n       [-0.102794  ],\n       [-0.04402008],\n       [ 0.05456663],\n       [-0.00286707],\n       [ 0.04923049],\n       [ 0.06129988],\n       [-0.1071667 ],\n       [-0.04682006],\n       [ 0.09202806],\n       [-0.03942909],\n       [ 0.00161189],\n       [-0.10278732],\n       [-0.05605689],\n       [-0.02060086],\n       [-0.02899172],\n       [-0.06869524],\n       [-0.03578011],\n       [ 0.06385375],\n       [-0.02737089],\n       [ 0.10330304],\n       [ 0.02007135],\n       [-0.10650741],\n       [-0.07607955],\n       [-0.09867048],\n       [-0.07565767],\n       [-0.08479752],\n       [-0.03756151],\n       [-0.03158976],\n       [-0.00265876],\n       [ 0.05647215],\n       [ 0.05687033],\n       [-0.03191116],\n       [ 0.05805456],\n       [ 0.02190227],\n       [-0.03437785],\n       [ 0.00162238],\n       [-0.03126787],\n       [-0.09851822],\n       [-0.10078083],\n       [ 0.04062773],\n       [-0.03500426],\n       [-0.08622383],\n       [ 0.01809485],\n       [-0.00971025],\n       [ 0.0588892 ],\n       [ 0.0569072 ],\n       [-0.05617474],\n       [-0.06943017],\n       [ 0.02391327],\n       [-0.02965691],\n       [-0.02049321],\n       [-0.0454161 ],\n       [ 0.07050855],\n       [-0.07810002],\n       [-0.10418994],\n       [ 0.06959146],\n       [-0.06962967],\n       [ 0.08480021],\n       [ 0.02422138],\n       [-0.10018951],\n       [-0.09814312],\n       [-0.00978637],\n       [ 0.08563466],\n       [-0.09370915],\n       [ 0.08082979],\n       [ 0.10003053],\n       [-0.01179931],\n       [-0.08688618],\n       [ 0.0037843 ],\n       [-0.05356823],\n       [-0.01561777],\n       [ 0.06461708],\n       [ 0.0187368 ],\n       [ 0.09526829],\n       [-0.02661556],\n       [-0.02913673],\n       [ 0.04797333],\n       [-0.06959439],\n       [-0.06903858],\n       [ 0.05997748],\n       [ 0.01823122],\n       [ 0.0789294 ],\n       [ 0.0453143 ],\n       [-0.067961  ],\n       [ 0.05554702],\n       [-0.0816751 ],\n       [-0.02673639],\n       [-0.08040643],\n       [ 0.0263418 ],\n       [ 0.02129688],\n       [ 0.06599038],\n       [-0.05747054],\n       [ 0.08564938],\n       [-0.01626712],\n       [ 0.02463696],\n       [ 0.05775597],\n       [ 0.02660396],\n       [-0.10205033],\n       [ 0.01960761],\n       [ 0.07695984],\n       [-0.05729291],\n       [ 0.06426648],\n       [ 0.0315185 ],\n       [ 0.02330559],\n       [ 0.03427183],\n       [-0.06915897],\n       [-0.07804051],\n       [ 0.10608014],\n       [ 0.01423877],\n       [ 0.03042435],\n       [ 0.08902542],\n       [-0.00847124],\n       [-0.09515831],\n       [ 0.04632234],\n       [-0.04610359],\n       [ 0.04975074],\n       [ 0.0284401 ],\n       [-0.05407291],\n       [-0.02036408],\n       [ 0.04581582],\n       [ 0.01597689],\n       [-0.01708307],\n       [ 0.06378212],\n       [ 0.07888366],\n       [-0.08079287],\n       [ 0.0189387 ],\n       [ 0.06372195],\n       [-0.0603364 ],\n       [ 0.08799932],\n       [ 0.03803686],\n       [ 0.03023384],\n       [ 0.00385363],\n       [ 0.06400204],\n       [-0.10184619],\n       [-0.05170293],\n       [ 0.09193157],\n       [-0.08202835],\n       [ 0.07491288],\n       [ 0.02509766],\n       [ 0.00086679],\n       [ 0.03467453],\n       [ 0.00258112],\n       [ 0.07459175],\n       [ 0.09609743],\n       [-0.06619255],\n       [ 0.02339985],\n       [ 0.02592931],\n       [-0.06280623],\n       [ 0.01296058],\n       [ 0.01017865],\n       [-0.07984387],\n       [ 0.07118803],\n       [-0.05747614],\n       [-0.01490323],\n       [ 0.04050807],\n       [-0.01014163],\n       [ 0.06163982],\n       [ 0.01297306],\n       [ 0.0188277 ],\n       [-0.04856383],\n       [ 0.00251035],\n       [ 0.01403932],\n       [-0.08761882],\n       [ 0.02140794],\n       [ 0.04351456],\n       [ 0.03899743],\n       [-0.02292006],\n       [-0.07050693],\n       [-0.07461101],\n       [ 0.07991014],\n       [ 0.03174488],\n       [-0.00422289],\n       [-0.1027167 ],\n       [ 0.0955699 ],\n       [-0.093398  ],\n       [ 0.04913274],\n       [-0.0059381 ],\n       [-0.0081662 ],\n       [-0.0836933 ],\n       [ 0.10642829],\n       [-0.01096556],\n       [ 0.02589924],\n       [-0.04409132],\n       [ 0.00621456],\n       [ 0.01453544],\n       [ 0.0621173 ],\n       [ 0.08526992],\n       [ 0.07076516],\n       [-0.08120283],\n       [ 0.06020469],\n       [-0.10169811],\n       [ 0.09183972],\n       [ 0.06675334],\n       [-0.06785941],\n       [ 0.07197275],\n       [-0.02273764],\n       [-0.06278078],\n       [-0.00161701],\n       [-0.09609604],\n       [-0.10378538],\n       [-0.08760154],\n       [-0.03358284],\n       [-0.04592723],\n       [-0.04103489],\n       [-0.05768226],\n       [-0.0772603 ],\n       [ 0.10668693],\n       [-0.03670102],\n       [ 0.06827214],\n       [ 0.09594228],\n       [-0.08979456],\n       [ 0.06675435],\n       [-0.07903097],\n       [-0.04329067],\n       [-0.05336146],\n       [-0.09882552],\n       [-0.02818789],\n       [ 0.07298801],\n       [ 0.00301247],\n       [-0.08703372],\n       [ 0.04992072],\n       [ 0.07118898],\n       [-0.04942648],\n       [-0.05570348],\n       [ 0.04119345],\n       [-0.04000819],\n       [ 0.06064779],\n       [-0.06969202],\n       [ 0.07509819],\n       [ 0.09904092],\n       [ 0.0779135 ],\n       [-0.01323235],\n       [ 0.08825807],\n       [ 0.03019417],\n       [-0.01313903],\n       [-0.00064544],\n       [ 0.00094208],\n       [ 0.06151632],\n       [-0.05032117],\n       [ 0.0935078 ],\n       [-0.02938331],\n       [ 0.09027704],\n       [ 0.0273779 ],\n       [ 0.05760016],\n       [ 0.03152586],\n       [-0.05730939],\n       [ 0.02181495],\n       [ 0.00835103],\n       [-0.09400631],\n       [-0.05575982],\n       [-0.05776159],\n       [-0.03434384],\n       [-0.06313205],\n       [ 0.06278744],\n       [-0.02040774],\n       [ 0.05244531],\n       [ 0.02375471],\n       [ 0.02892359],\n       [-0.02703799],\n       [-0.01940044],\n       [-0.02489647],\n       [-0.04528507],\n       [-0.08699866],\n       [-0.10756904],\n       [-0.09727361],\n       [ 0.04288477],\n       [-0.0111689 ],\n       [ 0.02985125],\n       [ 0.05621345],\n       [-0.01724971],\n       [ 0.04253436],\n       [ 0.01837481],\n       [-0.03108237],\n       [ 0.10153694],\n       [ 0.01564407],\n       [ 0.06746169],\n       [ 0.06484609],\n       [ 0.0110819 ],\n       [ 0.09983911],\n       [ 0.08969597],\n       [-0.00909539],\n       [ 0.07828154],\n       [-0.09779216],\n       [-0.01196326],\n       [ 0.08279642],\n       [-0.03756947],\n       [ 0.01169423],\n       [ 0.05584314],\n       [ 0.10616394],\n       [ 0.03685906],\n       [-0.0944571 ],\n       [-0.06884909],\n       [-0.03698491],\n       [-0.0644052 ],\n       [-0.07333682],\n       [-0.06534904],\n       [-0.09566057],\n       [ 0.09295567],\n       [ 0.03985926],\n       [ 0.04128218],\n       [ 0.10414182],\n       [-0.0887676 ],\n       [ 0.07109386],\n       [-0.00549608],\n       [ 0.03097614],\n       [ 0.02251814],\n       [ 0.04584526],\n       [-0.06751212],\n       [-0.01626462],\n       [-0.10268189],\n       [ 0.04930862],\n       [-0.07270884],\n       [-0.08482359],\n       [ 0.01063632],\n       [ 0.03956982],\n       [-0.01253746],\n       [-0.0582352 ],\n       [ 0.03968433],\n       [-0.07431678],\n       [-0.07106318],\n       [-0.08714227],\n       [-0.06272048],\n       [-0.04581584],\n       [-0.07426691],\n       [ 0.06288967],\n       [-0.02165247],\n       [ 0.03684939],\n       [ 0.04582316],\n       [ 0.03051168],\n       [-0.01722115],\n       [ 0.09401972],\n       [-0.06038526],\n       [-0.0901171 ],\n       [ 0.01009405],\n       [ 0.09278666],\n       [ 0.04209719],\n       [-0.04218614],\n       [ 0.08334934],\n       [ 0.05898301],\n       [ 0.01242236],\n       [ 0.1016928 ],\n       [-0.08741335],\n       [ 0.03004786],\n       [ 0.09923992],\n       [-0.10509523],\n       [ 0.00478164],\n       [-0.01805514],\n       [ 0.01001517],\n       [ 0.07229102],\n       [-0.0443783 ],\n       [ 0.10799103],\n       [ 0.05780677],\n       [-0.00669791],\n       [ 0.05262166],\n       [-0.0099634 ],\n       [ 0.02856811],\n       [ 0.00373577],\n       [ 0.03522485],\n       [ 0.03229143],\n       [ 0.02383093],\n       [-0.09154486],\n       [-0.06162036],\n       [-0.10070309],\n       [-0.09243377],\n       [ 0.10196122],\n       [-0.05718529],\n       [ 0.04102092],\n       [-0.04160354],\n       [ 0.08139772],\n       [-0.05612939],\n       [ 0.10373784],\n       [-0.01933033],\n       [-0.03988055],\n       [-0.0328181 ],\n       [ 0.09328339],\n       [-0.0475889 ],\n       [ 0.03473452],\n       [ 0.05494135],\n       [-0.00698966],\n       [-0.04073649],\n       [-0.04987554],\n       [ 0.07507185],\n       [ 0.10225149],\n       [ 0.10691313],\n       [ 0.07278521],\n       [ 0.10288087],\n       [-0.03786256],\n       [ 0.0574557 ],\n       [ 0.08847768],\n       [-0.08132777],\n       [ 0.10523083],\n       [-0.10551995],\n       [ 0.0768742 ],\n       [-0.06257743],\n       [-0.0749595 ],\n       [ 0.01995932],\n       [ 0.02739056],\n       [ 0.00937738],\n       [-0.00570377],\n       [-0.05108826],\n       [ 0.03726982],\n       [ 0.02009971],\n       [ 0.01162115],\n       [ 0.03771506],\n       [-0.03966564],\n       [ 0.02742057],\n       [ 0.08646648],\n       [ 0.05580644],\n       [ 0.06376054],\n       [-0.03508532],\n       [ 0.04100805],\n       [-0.08997928],\n       [-0.08892398],\n       [-0.00038746],\n       [ 0.03444044],\n       [-0.0624007 ],\n       [ 0.07332093],\n       [-0.02124485],\n       [ 0.01717455],\n       [-0.04208811],\n       [ 0.08208876],\n       [ 0.03242838],\n       [-0.0019097 ],\n       [ 0.03602735],\n       [ 0.00870585],\n       [ 0.0628138 ],\n       [ 0.05909718],\n       [-0.05822391],\n       [ 0.03534196],\n       [-0.06756137],\n       [ 0.05740882],\n       [-0.01425429],\n       [-0.07464543],\n       [-0.06228918],\n       [-0.05173008],\n       [ 0.02379601],\n       [ 0.04504641],\n       [-0.07603554],\n       [ 0.00462461],\n       [ 0.06875473],\n       [-0.0758525 ],\n       [ 0.02315687],\n       [-0.07942596],\n       [-0.09788707],\n       [-0.00866555],\n       [-0.06547502],\n       [-0.03726877],\n       [-0.05656713],\n       [ 0.02796014],\n       [ 0.03005303],\n       [-0.02500574],\n       [ 0.06041852],\n       [-0.06423479],\n       [-0.09297948],\n       [-0.01597235],\n       [ 0.03029697],\n       [ 0.0497173 ],\n       [ 0.04129738],\n       [-0.06631015],\n       [-0.0030141 ],\n       [ 0.011915  ],\n       [-0.03154897],\n       [ 0.02943196],\n       [ 0.07503884],\n       [ 0.04402336],\n       [ 0.02069136],\n       [-0.05550151],\n       [ 0.01433084],\n       [ 0.09005003],\n       [ 0.05974536],\n       [ 0.01499587],\n       [ 0.00088538],\n       [ 0.05604801],\n       [-0.02704281],\n       [ 0.06300949],\n       [-0.06339739],\n       [-0.1040004 ],\n       [-0.08297405],\n       [ 0.10006034]], dtype=float32)>: ['v/kernel']\n    <tf.Variable 'v/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>: ['v/bias']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESToLzAkYKED"
      },
      "source": [
        "coach = Coach(game, nnet, args)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uJRc2aRVjN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "089f998f-107b-406a-b63a-9341984a91df"
      },
      "source": [
        "%time coach.learn()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 02:33:22 ef2865b44f7b Coach[72] INFO Starting Iter #1 ...\n",
            "\n",
            "Self Play:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Self Play: 100%|██████████| 1/1 [00:53<00:00, 53.60s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Checkpoint Directory exists! \n",
            "./temp/ temp.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-73d96d31f0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time coach.learn()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/content/alpha-zero-general/Coach.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# training new network, keeping a copy of the old one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mpmcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/alpha-zero-general/othello/keras/NNet.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(self, folder, filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No model in path {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4CdwwNWd6vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816ff6ae-bce2-467f-c89a-0a92e05611c6"
      },
      "source": [
        "# Checkpoints and best model (if found) will be saved in this folder\n",
        "%ls /content/alpha-zero-general/temp/"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint                     temp.pth.tar.data-00000-of-00001\n",
            "checkpoint_0.pth.tar.examples  temp.pth.tar.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqyVWmYj_Gc8"
      },
      "source": [
        "!git pull origin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6qgtbCQeS8a"
      },
      "source": [
        "!cp /content/alpha-zero-general/temp/temp.pth.tar.index pretrained_models/othello/keras/8x8/checkpoint.index"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_1emvHmAho2"
      },
      "source": [
        "!touch pretrained_models/othello/keras/8x8/best.pth.tar"
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}